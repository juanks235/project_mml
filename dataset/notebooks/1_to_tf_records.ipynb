{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f692a43f-2eb8-476e-b0ca-a0068db09c7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Analisis de datos\n",
    "\n",
    "En este notebook convierte los datos descargados en el notebook 0_preprocessing.ipynb en tfrecords para usar tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4411ad-da8f-4c13-b771-38837ce45ee0",
   "metadata": {},
   "source": [
    "# Prerequisitos\n",
    "\n",
    "Es necesario ejecutar el notebook 0_preprocessing.ipynb para crear los ejemplos en formato npy antes de ejecutar este notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d8ea74-c351-4339-9d4d-7b7f567ab612",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3ecd5a-bb8e-4ef5-8475-34f74c6d3b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\santi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "import json\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84d85a5-26ca-4a44-93cb-d64715ad212d",
   "metadata": {},
   "source": [
    "# Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2829f5b7-20ff-423d-aee7-8c6e65810478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpeta para guardar ejemplos estandarizados y limpios\n",
    "CLEANED_DATASET_FOLDER = \"../../cleaned_data\"\n",
    "# Tensorflow dataset folder\n",
    "TF_DATASET_FOLDER = \"../tf_data\"\n",
    "# Chunk size\n",
    "CHUNK_SIZE = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e49605d-8acf-4365-b510-c00b20bfb5c9",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08786a54-587b-4b35-864b-d3cf25a6278e",
   "metadata": {},
   "source": [
    "## Generacion de tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0441215-3a1c-4c34-a53e-9df1bae7c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()])\n",
    "    )\n",
    "\n",
    "def bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n",
    "\n",
    "\n",
    "def float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def float_feature_list(value):\n",
    "    \"\"\"Returns a list of float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ae7da8-3f44-4c88-bcc4-b4c2a0f77881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(example):\n",
    "    feature = {\n",
    "        \"song_id\": int64_feature(example[\"song_id\"]),\n",
    "        \"genre_id\": int64_feature(example[\"genre_id\"]),\n",
    "        \"time_series\": float_feature_list(example[\"time_series\"])\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d3f9c-1cad-4201-ac81-ddbae7983c34",
   "metadata": {},
   "source": [
    "## Iteracion sobre npy a tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf3b24c-e2c3-4ced-9546-84f93ea6c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_npy_files():\n",
    "    npy_files = [\n",
    "        os.path.join(CLEANED_DATASET_FOLDER, npy_file)\n",
    "        for npy_file in os.listdir(CLEANED_DATASET_FOLDER) \n",
    "    ]\n",
    "    random.shuffle(npy_files)\n",
    "    return npy_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "635bb631-ad92-4653-ab4b-a1a2cd0225cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_chunks(files, chunk_size): \n",
    "    return {\n",
    "        f\"chunk_{i}\": files[i:i + chunk_size]\n",
    "        for i in range(0, len(files), chunk_size)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac356d10-32b6-4336-94cf-7b348e94d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_to_tf_record(chunk_id, chunk_files):\n",
    "    with tf.io.TFRecordWriter(\n",
    "        os.path.join(TF_DATASET_FOLDER, f\"{chunk_id}.tfrecord\")\n",
    "    ) as writer:\n",
    "        for file in chunk_files:\n",
    "            example = np.load(file, allow_pickle=True).tolist()\n",
    "            tf_example = create_tf_example(example)\n",
    "            writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87acef6c-fe97-452f-99da-93b149ea99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npy_dataset_to_tfrecords():\n",
    "    if not os.path.exists(TF_DATASET_FOLDER):\n",
    "        os.mkdir(TF_DATASET_FOLDER)\n",
    "    npy_files = list_npy_files()\n",
    "    chunks = divide_chunks(npy_files, CHUNK_SIZE)\n",
    "    _ = Parallel(n_jobs=-1, verbose=10)(\n",
    "        delayed(chunk_to_tf_record)(\n",
    "            chunk_id,\n",
    "            chunk_files\n",
    "        )\n",
    "        for chunk_id, chunk_files in chunks.items()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4dc03-462c-4b98-8ce2-8bd6be7e4e1c",
   "metadata": {},
   "source": [
    "## Lectura de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d33ee9a3-23c8-4d66-8444-179c2ee2025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(tfrecord_folder):\n",
    "    tf_record_files = [\n",
    "        os.path.join(tfrecord_folder, file)\n",
    "        for file in\n",
    "        os.listdir(tfrecord_folder)\n",
    "    ]\n",
    "    return tf.data.TFRecordDataset(tf_record_files).map(parse_tfrecord_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "085e3631-6d86-4028-94a1-56c4ed6c279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord_fn(tf_example):\n",
    "    feature_description = {\n",
    "        \"song_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"genre_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"time_series\": tf.io.VarLenFeature(tf.float32)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(tf_example, feature_description)\n",
    "    example[\"time_series\"] = tf.sparse.to_dense(example[\"time_series\"])\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d09d576-ebe3-4649-9972-72d9053312ac",
   "metadata": {},
   "source": [
    "# Generacion de tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90e4c3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\WIndowsRepositories\\\\project_mml\\\\dataset\\\\notebooks'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db4ebcf3-ac13-4b78-82de-83036d6861f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  14 | elapsed:   53.6s remaining:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  14 | elapsed:   54.0s remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:   54.3s remaining:   54.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  14 | elapsed:   54.4s remaining:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  14 | elapsed:   54.7s remaining:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:   55.0s finished\n"
     ]
    }
   ],
   "source": [
    "npy_dataset_to_tfrecords()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10a9e7-3415-4090-a23e-a95d72656268",
   "metadata": {},
   "source": [
    "# Lectura de tfrecords como dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4a7f3f9-09f0-40e9-859f-f646fe00dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(TF_DATASET_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71b6addc-018b-4436-aa6d-ce9aecd17cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec={'time_series': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'genre_id': TensorSpec(shape=(), dtype=tf.int64, name=None), 'song_id': TensorSpec(shape=(), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c00d2f4-5455-4654-9748-59551d345656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time_series': <tf.Tensor: shape=(1321967,), dtype=float32, numpy=\n",
      "array([-9.6101727e-10, -1.1001114e-08, -1.3324586e-08, ...,\n",
      "       -1.0322432e-01, -1.0536708e-01, -1.0047625e-01], dtype=float32)>, 'genre_id': <tf.Tensor: shape=(), dtype=int64, numpy=5>, 'song_id': <tf.Tensor: shape=(), dtype=int64, numpy=3796>}\n",
      "{'time_series': <tf.Tensor: shape=(1321967,), dtype=float32, numpy=\n",
      "array([-3.22965810e-09, -4.43648602e-08, -1.15803765e-07, ...,\n",
      "       -4.44202453e-01, -4.89289045e-01, -5.32377601e-01], dtype=float32)>, 'genre_id': <tf.Tensor: shape=(), dtype=int64, numpy=5>, 'song_id': <tf.Tensor: shape=(), dtype=int64, numpy=18028>}\n",
      "{'time_series': <tf.Tensor: shape=(1321967,), dtype=float32, numpy=\n",
      "array([-0.05667935, -0.05044877, -0.02995109, ...,  0.04404794,\n",
      "        0.0305051 ,  0.01628765], dtype=float32)>, 'genre_id': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'song_id': <tf.Tensor: shape=(), dtype=int64, numpy=21426>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-27 22:05:09.897613: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for example in dataset.take(3):\n",
    "  print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a4bec6-68c1-4b71-9669-247233048cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
