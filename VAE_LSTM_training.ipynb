{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from Pytorch_VAE_LSTM import VAE\n",
    "from dataset.modules.music_dataset import TorchMusicDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dataset = TorchMusicDataset(\"./dataset/cleaned_data/cleaned_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = []\n",
    "for i in range(700):\n",
    "    obj = dataset.__getitem__(i)\n",
    "    song = obj['time_series'].numpy()[:-7]\n",
    "    reduce_mean_song = np.mean(song.reshape(-1, 40), axis=1) \n",
    "    songs.append(reduce_mean_song.reshape(reduce_mean_song.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33049, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.07434827089309692\n",
      "Epoch 10, Loss: 0.03756450489163399\n",
      "Epoch 20, Loss: 0.023068726062774658\n",
      "Epoch 30, Loss: 0.04853392392396927\n",
      "Epoch 40, Loss: 0.03283509239554405\n",
      "Epoch 50, Loss: 0.021407639607787132\n",
      "Epoch 60, Loss: 0.024609077721834183\n",
      "Epoch 70, Loss: 0.0228077732026577\n",
      "Epoch 80, Loss: 0.02469830960035324\n",
      "Epoch 90, Loss: 0.031313106417655945\n",
      "Epoch 100, Loss: 0.040324315428733826\n",
      "Epoch 110, Loss: 0.04006321355700493\n",
      "Epoch 120, Loss: 0.04513774812221527\n",
      "Epoch 130, Loss: 0.03620599955320358\n",
      "Epoch 140, Loss: 0.030614370480179787\n",
      "Epoch 150, Loss: 0.02321167103946209\n",
      "Epoch 160, Loss: 0.04040929302573204\n",
      "Epoch 170, Loss: 0.029920071363449097\n",
      "Epoch 180, Loss: 0.027222048491239548\n",
      "Epoch 190, Loss: 0.0470939576625824\n",
      "Epoch 200, Loss: 0.020496850833296776\n",
      "Epoch 210, Loss: 0.03050239384174347\n",
      "Epoch 220, Loss: 0.027865465730428696\n",
      "Epoch 230, Loss: 0.03592591732740402\n",
      "Epoch 240, Loss: 0.029831642284989357\n",
      "Epoch 250, Loss: 0.03239224851131439\n",
      "Epoch 260, Loss: 0.02272106148302555\n",
      "Epoch 270, Loss: 0.03701433166861534\n",
      "Epoch 280, Loss: 0.02133202739059925\n",
      "Epoch 290, Loss: 0.04125206544995308\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "n_in = songs[0].shape[0]\n",
    "songs = np.array(songs)\n",
    "songs = torch.tensor(songs, dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(songs, songs) \n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "vae = VAE(timesteps=n_in, features=1, latent_dim=4, device=device).to(device)\n",
    "vae.optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "epochs = 300\n",
    "for epoch in range(epochs):\n",
    "    for batch_x, _ in dataloader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        loss = vae.training_step(batch_x)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss}')\n",
    "    \n",
    "num_samples = 1\n",
    "generated_sequences = vae.generate_sequences(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_songs = []\n",
    "for sequence in generated_sequences:\n",
    "    reconstructed_song = np.repeat(reduce_mean_song, 40, axis=0)\n",
    "    reconstructed_songs.append(reconstructed_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0124829e-06, -1.0124829e-06, -1.0124829e-06, ...,\n",
       "       -3.6045098e-01, -3.6045098e-01, -3.6045098e-01], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_songs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved as output_audio.wav\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# Example usage\n",
    "audio_array = reconstructed_songs[0]  # Replace with your actual audio array\n",
    "sample_rate = 44100  # Replace with your actual sample rate\n",
    "\n",
    "# Normalize the audio array to be within the range [-1, 1]\n",
    "audio_array = audio_array / np.max(np.abs(audio_array))\n",
    "\n",
    "# Convert the normalized audio array to 16-bit PCM format\n",
    "audio_array = (audio_array * 32767).astype(np.int16)\n",
    "\n",
    "# Save the audio array as a .wav file\n",
    "output_filename = 'output_audio.wav'\n",
    "write(output_filename, sample_rate, audio_array)\n",
    "\n",
    "print(f\"Audio saved as {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
