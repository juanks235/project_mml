{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b323c2-236d-4ca6-bd12-1deb826f9fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "from CVAE import Resnet1DBlock, CVAE, calculate_output_shape_convtranspose\n",
    "from music_dataset import TorchMusicDataset\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6083c38e-e535-49b1-8efc-14df4b41d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SECONDS = 2\n",
    "DOWNSAMPLE_RATIO = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44ed6f6a-40cf-42ce-89fe-c6fd00e19c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "BATCH_SIZE = 2\n",
    "LATENT_DIM = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c5a837c-7103-465d-b9e2-5f3609fe9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_device(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c6486b2-dc29-4eec-8f18-ee4341838e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4410)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TorchMusicDataset(\"../cleaned_data\", N_SECONDS, DOWNSAMPLE_RATIO)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "n_features, n_timesteps  = dataset.__getitem__(1).shape\n",
    "n_features, n_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b5a65a4-ea8b-48f3-bed4-4ebd663cdf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b75c86ef-7623-4f59-8ff6-8535b96acf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae = CVAE(LATENT_DIM, DEVICE, n_timesteps, BATCH_SIZE).to(DEVICE)\n",
    "cvae.optimizer = optim.Adam(cvae.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3012a00c-a237-419b-9325-5f384511f4fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johan/.cache/pypoetry/virtualenvs/mml-project-ItOqwNvu-py3.11/lib/python3.11/site-packages/torch/utils/_device.py:79: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1031.)\n",
      "  return func(*args, **kwargs)\n",
      "/home/johan/.cache/pypoetry/virtualenvs/mml-project-ItOqwNvu-py3.11/lib/python3.11/site-packages/torch/nn/modules/instancenorm.py:88: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
      "  warnings.warn(f\"input's size at dim={feature_dim} does not match num_features. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4234396821260452\n",
      "1 0.26102894350886346\n",
      "2 0.17971415422856807\n",
      "3 0.19547316752374172\n",
      "4 0.18429199293255805\n",
      "5 0.19280827149748803\n",
      "6 0.1600872442126274\n",
      "7 0.18140337064862253\n",
      "8 0.16676100827753543\n",
      "9 0.19960481844842434\n",
      "10 0.19678015895187856\n",
      "11 0.14810525439679623\n",
      "12 0.17210095398128034\n",
      "13 0.1861790668964386\n",
      "14 0.1858897364884615\n",
      "15 0.1699416770040989\n",
      "16 0.16080526750534774\n",
      "17 0.18415784694254397\n",
      "18 0.1939677257835865\n",
      "19 0.1917008064687252\n",
      "20 0.18411960527300836\n",
      "21 0.2163825024664402\n",
      "22 0.18408796913921832\n",
      "23 0.18245952300727367\n",
      "24 0.20931226000189782\n",
      "25 0.1864846894145012\n",
      "26 0.18173902556300164\n",
      "27 0.17388261444866657\n",
      "28 0.18959308102726935\n",
      "29 0.16258222706615924\n",
      "30 0.17344501614570618\n",
      "31 0.19687197580933571\n",
      "32 0.1929529318213463\n",
      "33 0.1768783188611269\n",
      "34 0.19287771806120874\n",
      "35 0.20295538626611231\n",
      "36 0.18366374909877778\n",
      "37 0.20159560821950437\n",
      "38 0.19222786702215672\n",
      "39 0.19800915598869323\n",
      "40 0.1661548388749361\n",
      "41 0.20432084575295448\n",
      "42 0.19686425276100636\n",
      "43 0.19122443109750747\n",
      "44 0.18449353456497192\n",
      "45 0.18079259432852268\n",
      "46 0.18377143621444703\n",
      "47 0.2016821651160717\n",
      "48 0.19033314369618892\n",
      "49 0.18654653832316398\n",
      "50 0.15883630275726318\n",
      "51 0.18107707761228084\n",
      "52 0.19991630494594573\n",
      "53 0.19340579368174077\n",
      "54 0.17958511158823967\n",
      "55 0.20110169872641565\n",
      "56 0.2109706234931946\n",
      "57 0.1736835567653179\n",
      "58 0.19023022517561913\n",
      "59 0.18365618348121643\n",
      "60 0.1505144614726305\n",
      "61 0.18208394810557366\n",
      "62 0.1814807315915823\n",
      "63 0.1840105301886797\n",
      "64 0.17568550780415534\n",
      "65 0.17741926327347757\n",
      "66 0.18543449424207212\n",
      "67 0.17090753078460694\n",
      "68 0.16763690747320653\n",
      "69 0.1718476840481162\n",
      "70 0.18665470696985723\n",
      "71 0.19735409647226335\n",
      "72 0.19071492820978164\n",
      "73 0.18073263198137282\n",
      "74 0.18159767858684062\n",
      "75 0.18857475854456424\n",
      "76 0.17086016178131103\n",
      "77 0.18044608809053897\n",
      "78 0.19004875734448434\n",
      "79 0.18482358813285826\n",
      "80 0.17588755913078785\n",
      "81 0.20528353340923786\n",
      "82 0.20246092148125172\n",
      "83 0.17296554118394852\n",
      "84 0.1644727708399296\n",
      "85 0.16599398992955686\n",
      "86 0.19191385596990584\n",
      "87 0.16980008244514466\n",
      "88 0.19356913283467292\n",
      "89 0.19359536409378053\n",
      "90 0.1789621666073799\n",
      "91 0.15654026962816714\n",
      "92 0.19487051378935574\n",
      "93 0.18193235740065575\n",
      "94 0.19258738562464714\n",
      "95 0.18310851559042932\n",
      "96 0.18622581347823142\n",
      "97 0.1897954086959362\n",
      "98 0.168439312428236\n",
      "99 0.19035636454820634\n",
      "100 0.2006215660274029\n",
      "101 0.16799122840166092\n",
      "102 0.20816132217645644\n",
      "103 0.19011426955461502\n",
      "104 0.17117515444755554\n",
      "105 0.20210316866636277\n",
      "106 0.16414542131125928\n",
      "107 0.2027430385351181\n",
      "108 0.17917468942701817\n",
      "109 0.19332857452332974\n",
      "110 0.1785043665021658\n",
      "111 0.17549361914396286\n",
      "112 0.17707811608910562\n",
      "113 0.18719422444701195\n",
      "114 0.17948941260576248\n",
      "115 0.18858561128377915\n",
      "116 0.16823918223381043\n",
      "117 0.18625701494514943\n",
      "118 0.17240164846181869\n",
      "119 0.17595242507755757\n",
      "120 0.18425241377204657\n",
      "121 0.17874716006219388\n",
      "122 0.17130132354795932\n",
      "123 0.18260938480496405\n",
      "124 0.17846285603940487\n",
      "125 0.17329027377068995\n",
      "126 0.17013816524296999\n",
      "127 0.1917851126194\n",
      "128 0.16614406369626522\n",
      "129 0.188807482868433\n",
      "130 0.17173253670334815\n",
      "131 0.16037113711237908\n",
      "132 0.16766705997288228\n",
      "133 0.18153744034469127\n",
      "134 0.1701017065346241\n",
      "135 0.1745352866500616\n",
      "136 0.19726079657673837\n",
      "137 0.16537441916763782\n",
      "138 0.17781382009387017\n",
      "139 0.2031434404850006\n",
      "140 0.17970316298305988\n",
      "141 0.17546339958906174\n",
      "142 0.2125111373513937\n",
      "143 0.17644388191401958\n",
      "144 0.16937232434749602\n",
      "145 0.174562216848135\n",
      "146 0.19618699088692665\n",
      "147 0.18324202008545398\n",
      "148 0.1840107908844948\n",
      "149 0.1740028603374958\n",
      "150 0.16951815016567706\n",
      "151 0.18524026334285737\n",
      "152 0.19828321650624275\n",
      "153 0.19495807200670243\n",
      "154 0.18253660701215269\n",
      "155 0.1713063772022724\n",
      "156 0.17366624653339385\n",
      "157 0.17287460170686245\n",
      "158 0.18725226640701295\n",
      "159 0.1742892674356699\n",
      "160 0.16991915047168732\n",
      "161 0.18050603859126568\n",
      "162 0.1962934796512127\n",
      "163 0.1906137855350971\n",
      "164 0.17708244204521179\n",
      "165 0.19713002055883408\n",
      "166 0.18737255625426769\n",
      "167 0.16178812071681023\n",
      "168 0.18623688735067845\n",
      "169 0.17075360491871833\n",
      "170 0.19879754669964314\n",
      "171 0.19288952879607676\n",
      "172 0.1861253024637699\n",
      "173 0.19322409242391586\n",
      "174 0.16657134905457496\n",
      "175 0.19665615931153296\n",
      "176 0.17821643210947513\n",
      "177 0.18803474731743336\n",
      "178 0.20461637072265149\n",
      "179 0.18081663869321346\n",
      "180 0.18789008110761643\n",
      "181 0.17515530847012997\n",
      "182 0.21493384160101414\n",
      "183 0.20000064827501773\n",
      "184 0.17799434095621108\n",
      "185 0.19211448885500432\n",
      "186 0.18037985756993294\n",
      "187 0.1831537826359272\n",
      "188 0.17520636189728975\n",
      "189 0.17570381335914134\n",
      "190 0.19382170483469963\n",
      "191 0.19924238927662372\n",
      "192 0.1727952205389738\n",
      "193 0.16570099495351315\n",
      "194 0.1771024112403393\n",
      "195 0.19477397650480271\n",
      "196 0.19085519552230834\n",
      "197 0.18225064355880022\n",
      "198 0.17302397042512893\n",
      "199 0.17913094468414784\n",
      "200 0.19859207220375538\n",
      "201 0.1973353837430477\n",
      "202 0.18135347083210945\n",
      "203 0.19854945778846741\n",
      "204 0.1882635571807623\n",
      "205 0.19438896961510183\n",
      "206 0.17525969445705414\n",
      "207 0.18365923285484315\n",
      "208 0.17908104315400122\n",
      "209 0.1906771579384804\n",
      "210 0.1884773114323616\n",
      "211 0.1825247000157833\n",
      "212 0.17898462567478418\n",
      "213 0.17100272834300995\n",
      "214 0.1884511709958315\n",
      "215 0.16810206338763237\n",
      "216 0.1787477733194828\n",
      "217 0.17583248198032378\n",
      "218 0.18701377987861634\n",
      "219 0.17801977977156638\n",
      "220 0.21354919627308847\n",
      "221 0.17831641793251038\n",
      "222 0.18785959772765637\n",
      "223 0.1932502941787243\n",
      "224 0.17002635292708873\n",
      "225 0.18070259846746922\n",
      "226 0.19034305840730667\n",
      "227 0.1816141626238823\n",
      "228 0.1840120069682598\n",
      "229 0.19011230245232583\n",
      "230 0.18219425037503242\n",
      "231 0.19254915535449982\n",
      "232 0.18669474214315415\n",
      "233 0.17790187440812588\n",
      "234 0.19602125033736228\n",
      "235 0.18179561175405978\n",
      "236 0.19737403646111487\n",
      "237 0.17454492539167404\n",
      "238 0.1849717317521572\n",
      "239 0.20045450448989868\n",
      "240 0.19546340472996235\n",
      "241 0.19202132746577263\n",
      "242 0.18828994564712048\n",
      "243 0.15969571366906166\n",
      "244 0.19093742609024048\n",
      "245 0.17124769367277623\n",
      "246 0.15579042814671992\n",
      "247 0.17589233532547952\n",
      "248 0.20301572501659393\n",
      "249 0.17826299287378788\n",
      "250 0.20852216139435767\n",
      "251 0.19232173204421998\n",
      "252 0.1867369969189167\n",
      "253 0.2027733725309372\n",
      "254 0.2207578930258751\n",
      "255 0.16291978776454927\n",
      "256 0.1818136490881443\n",
      "257 0.17082767602056265\n",
      "258 0.19595337055623532\n",
      "259 0.16294336296617984\n",
      "260 0.18285614512860776\n",
      "261 0.19703178346157074\n",
      "262 0.1778349493443966\n",
      "263 0.19017603531479835\n",
      "264 0.17051263310015202\n",
      "265 0.20317657731473446\n",
      "266 0.1936482833325863\n",
      "267 0.18464201897382737\n",
      "268 0.2076970374584198\n",
      "269 0.1666037953644991\n",
      "270 0.19063200429081917\n",
      "271 0.18834933802485465\n",
      "272 0.18544676244258881\n",
      "273 0.1891209901869297\n",
      "274 0.19283079966902733\n",
      "275 0.18330884393304586\n",
      "276 0.19264007277786732\n",
      "277 0.1985845710337162\n",
      "278 0.20014132365584372\n",
      "279 0.17966366052627564\n",
      "280 0.17150599479675294\n",
      "281 0.17985248133540155\n",
      "282 0.1884747575968504\n",
      "283 0.17116669811308383\n",
      "284 0.17265940248966216\n",
      "285 0.16217584133148194\n",
      "286 0.16905600264668463\n",
      "287 0.19607101023197174\n",
      "288 0.19232319548726082\n",
      "289 0.18863245591521263\n",
      "290 0.18817042097449302\n",
      "291 0.20858895570039748\n",
      "292 0.18779255256056784\n",
      "293 0.18265718325972558\n",
      "294 0.17910824805498124\n",
      "295 0.17262900829315186\n",
      "296 0.18028506577014924\n",
      "297 0.19847868576645852\n",
      "298 0.18600528344511985\n",
      "299 0.18485692381858826\n",
      "CPU times: user 1h 36min 39s, sys: 58.1 s, total: 1h 37min 38s\n",
      "Wall time: 1h 37min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    n_steps = 0\n",
    "    epoch_loss = 0\n",
    "    for batch_x in dataloader:\n",
    "        loss = cvae.training_step(batch_x)\n",
    "        epoch_loss += loss\n",
    "        n_steps += 1\n",
    "    epoch_loss /= n_steps\n",
    "    print(epoch, epoch_loss)\n",
    "    losses.append(epoch_loss)\n",
    "    with open(\"loss.json\", \"w\") as f:\n",
    "        json.dump(losses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f99066ad-ea56-4fee-bc8c-9cf6c6cc554c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4410)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sequences = cvae.generate_sequences(2)\n",
    "generated_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87aa99a9-949f-49d4-81f5-f08174aabef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved as gen_audio_VAE_LSTM.wav\n"
     ]
    }
   ],
   "source": [
    "output_filename = 'gen_audio_VAE_LSTM.wav'\n",
    "write(output_filename, 44100//DOWNSAMPLE_RATIO, generated_sequences[0])\n",
    "\n",
    "print(f\"Audio saved as {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92645bde-ec0d-4a29-a86a-d094b69c8849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
